- Overview
  - Talk on Search Engines + RAG
  - Search Engines
    - Why? - Can't scroll, Used everywhere
    - Why not dump into GPT? - Context Overflow + AI is expensive (time + resources)
  - RAG
    - Why? - Enhance + Maybe simplify + Better Understanding
- Search Algorithms
  - Preprocessing
    - Exact match use cases (not semantic)
    - Casing, punctuations
    - Tokenizing, fuzzy, stop words (meaningless - the = the - domain specific)
      - searching "const"
  - Full Text Search
    - We search the entire document for the query
    - We return the documents that contain the query (or a subset of the query)
    - Without ranking, we return the documents in the order they appear in the documents
    - Random token can appear in many documents, so we need to rank them
  - TF-IDF
    - We create indexes to make things fast (caching)
    - TF: Term Frequency - How many times does the term appear in the document?
    - IDF: Inverse Document Frequency - How rare is the term in the set (excluding stop words)?
    - Used to rank documents based on the importance of the terms in the query
    - TF-IDF = TF * (IDF = Number of documents / Number of documents containing the term)
    - TF-IDF is a measure of the importance of a term in all documents
    - The higher the TF-IDF, the more important the term is and vice versa
    - We can use TF-IDF to rank documents based on the importance of the terms in the query
    - We would want the documents having frequent terms from the query but also rare in the set to be ranked higher
  - BM25 TF-IDF
    - The problems with normal IDF
      - Very rare terms will have a very high IDF score
      - Very common terms will have a very low IDF score
      - log((N - Tf + 0.5) / (Tf + 0.5) + 1)
    - The problems with normal TF
      - Linear scaling
      - Very common terms will have a very high TF score (irrelevant keywords)
      - Very rare terms will have a very low TF score (It might be important, but not common)
      - (Tf * (k1 + 1)) / (Tf + k1)
      - Mean vs Median example
      - Document Length Normalization
        - We want to normalize the document length to the average length of the documents
        - 1 - b + b * (dl / avgdl)
  - Semantic Search
    - Problems with keyword search
      - Only exact matches are considered
      - No search with context, synonyms, antonyms, or related words
    - Selecting a model (based on use case, cost, performance, etc.)
      - Multilingual models
      - Domain specific models
    - Dimensions
      - Vector operations
    - Similarity search
      - Dot product (dp = a1 * b1 + a2 * b2 + ... + an * bn = direction similarity and don't consider magnitude/length)
      - Cosine similarity (cos(theta) = dp / (sqrt(a1^2 + a2^2 + ... + an^2) * sqrt(b1^2 + b2^2 + ... + bn^2)) = direction similarity and consider magnitude/length)
      - Similarity depends on the model used
      - Tokenization (static doesn't work as model is not trained on static tokens)
      - Vector DBs - specialized for vector storage and retrieval
      - Hot and cold game on Reddit
    - LSH (Locality Sensitive Hashing)
      - Hashing the vectors to a smaller space
      - May miss some similar vectors
    - Chunking
      - Fixed size chunking
      - Overlapping chunks
      - Semantic chunks
      - Needs lots of debugging and testing to cover edge cases and get the best results
        - Tables, multi page paragraphs, etc.
        - Headers, footers - repeated content across chunks
        - Image captions getting mixed up with text content
        - Column layouts, weird spacing/fonts, missing line breaks
        - Markdown formats
      - ColBERT - created embeddings per token
      - Late chunking - chunking after the embedding is created - summarization, etc. (pronouns, etc.)
      - Try using third party services to see if there's any improvements before implementing your own
  - Hybrid Search
    - Normalizing the scores from the different search algorithms
    - Basic - Weighted combination of the scores
      - Weighted - alpha (0.5 or 0.3 whatever works best for the use case)
      - Combination - balanced - not really well for one but really bad for the other - outer join
      - formula: alpha * bm25Score + (1 - alpha) * semanticScore
    - Reciprocal Rank Fusion
      - Basic hybrid search can penalize one algorithm over the other - hard to normalize the scores
      - Reciprocal Rank Fusion would boost results which are good in both algorithms - only cares about ranks and not the scores
      - formula: 1 / (rank + k)
